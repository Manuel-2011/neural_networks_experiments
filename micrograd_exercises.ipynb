{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnGHatCI51JP"
      },
      "source": [
        "# micrograd exercises\n",
        "\n",
        "1. watch the [micrograd video](https://www.youtube.com/watch?v=VMj-3S1tku0) on YouTube\n",
        "2. come back and complete these exercises to level up :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFt6NKOz6iBZ"
      },
      "source": [
        "## section 1: derivatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3Jx9fCXl5xHd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.336362190988558\n"
          ]
        }
      ],
      "source": [
        "# here is a mathematical expression that takes 3 inputs and produces one output\n",
        "from math import sin, cos\n",
        "\n",
        "def f(a, b, c):\n",
        "  return -a**3 + sin(3*b) - 1.0/c + b**2.5 - a**0.5\n",
        "\n",
        "print(f(2, 3, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qXaH59eL9zxf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK for dim 0: expected -12.353553390593273, yours returns -12.353553390593273\n",
            "OK for dim 1: expected 10.25699027111255, yours returns 10.25699027111255\n",
            "OK for dim 2: expected 0.0625, yours returns 0.0625\n"
          ]
        }
      ],
      "source": [
        "# write the function df that returns the analytical gradient of f\n",
        "# i.e. use your skills from calculus to take the derivative, then implement the formula\n",
        "# if you do not calculus then feel free to ask wolframalpha, e.g.:\n",
        "# https://www.wolframalpha.com/input?i=d%2Fda%28sin%283*a%29%29%29\n",
        "\n",
        "def gradf(a, b, c):\n",
        "  return [-3*a**2-0.5*a**(-0.5), 3*cos(3*b)+2.5*b**1.5, 1/c**2] # todo, return [df/da, df/db, df/dc]\n",
        "\n",
        "# expected answer is the list of\n",
        "ans = [-12.353553390593273, 10.25699027111255, 0.0625]\n",
        "yours = gradf(2, 3, 4)\n",
        "for dim in range(3):\n",
        "  ok = 'OK' if abs(yours[dim] - ans[dim]) < 1e-5 else 'WRONG!'\n",
        "  print(f\"{ok} for dim {dim}: expected {ans[dim]}, yours returns {yours[dim]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_27n-KTA9Qla"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK for dim 0: expected -12.353553390593273, yours returns -12.35355817641448\n",
            "OK for dim 1: expected 10.25699027111255, yours returns 10.256986371359744\n",
            "OK for dim 2: expected 0.0625, yours returns 0.06250111539429781\n"
          ]
        }
      ],
      "source": [
        "# now estimate the gradient numerically without any calculus, using\n",
        "# the approximation we used in the video.\n",
        "# you should not call the function df from the last cell\n",
        "\n",
        "# -----------\n",
        "diff = 1e-10\n",
        "numerical_grad = [(f(2+diff,3,4)-f(2,3,4))/diff, (f(2,3+diff,4)-f(2,3,4))/diff, (f(2,3,4+diff)-f(2,3,4))/diff] # TODO\n",
        "# -----------\n",
        "\n",
        "for dim in range(3):\n",
        "  ok = 'OK' if abs(numerical_grad[dim] - ans[dim]) < 1e-5 else 'WRONG!'\n",
        "  print(f\"{ok} for dim {dim}: expected {ans[dim]}, yours returns {numerical_grad[dim]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BUqsGb5o_h2P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK for dim 0: expected -12.353553390593273, yours returns -12.353553735522382\n",
            "OK for dim 1: expected 10.25699027111255, yours returns 10.256990812251843\n",
            "OK for dim 2: expected 0.0625, yours returns 0.06250111539429781\n"
          ]
        }
      ],
      "source": [
        "# there is an alternative formula that provides a much better numerical\n",
        "# approximation to the derivative of a function.\n",
        "# learn about it here: https://en.wikipedia.org/wiki/Symmetric_derivative\n",
        "# implement it. confirm that for the same step size h this version gives a\n",
        "# better approximation.\n",
        "\n",
        "# -----------\n",
        "numerical_grad2 = [(f(2+diff,3,4)-f(2-diff,3,4))/(2*diff), (f(2,3+diff,4)-f(2,3-diff,4))/(2*diff), (f(2,3,4+diff)-f(2,3,4-diff))/(2*diff)] # TODO\n",
        "# -----------\n",
        "\n",
        "for dim in range(3):\n",
        "  ok = 'OK' if abs(numerical_grad2[dim] - ans[dim]) < 1e-5 else 'WRONG!'\n",
        "  print(f\"{ok} for dim {dim}: expected {ans[dim]}, yours returns {numerical_grad2[dim]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tklF9s_4AtlI"
      },
      "source": [
        "## section 2: support for softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nAPe_RVrCTeO"
      },
      "outputs": [],
      "source": [
        "# Value class starter code, with many functions taken out\n",
        "from math import exp, log\n",
        "\n",
        "class Value:\n",
        "\n",
        "  def __init__(self, data, _children=(), _op='', label=''):\n",
        "    self.data = data\n",
        "    self.grad = 0.0\n",
        "    self._backward = lambda: None\n",
        "    self._prev = set(_children)\n",
        "    self._op = _op\n",
        "    self.label = label\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Value(data={self.data})\"\n",
        "\n",
        "  def __add__(self, other): # exactly as in the video\n",
        "    other = other if isinstance(other, Value) else Value(other)\n",
        "    out = Value(self.data + other.data, (self, other), '+')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += 1.0 * out.grad\n",
        "      other.grad += 1.0 * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "  # ------\n",
        "  # re-implement all the other functions needed for the exercises below\n",
        "  # your code here\n",
        "  def __radd__(self, other):\n",
        "    return self + other\n",
        "  \n",
        "  def exp(self):\n",
        "    out = Value(exp(self.data), (self,), 'exp')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += out.data * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def __mul__(self, other):\n",
        "    other = other if isinstance(other, Value) else Value(other)\n",
        "    out = Value(self.data * other.data, (self, other), '*')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += other.data * out.grad\n",
        "      other.grad += self.data * out.grad\n",
        "      print(self, self.grad)\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "\n",
        "  def __rmul__(self, other):\n",
        "    return self * other\n",
        "  \n",
        "  def __truediv__(self, other):\n",
        "    other = other if isinstance(other, Value) else Value(other)\n",
        "    out = Value(self.data / other.data, (self, other), '/')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += (1 / other.data) * out.grad\n",
        "      other.grad += -1 * (self.data / other.data**2) * out.grad\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def __neg__(self):\n",
        "    return self * -1\n",
        "  \n",
        "  def __sub__(self, other):\n",
        "    return self + (-other)\n",
        "  \n",
        "  def __rsub__(self, other):\n",
        "    return other + (-self)\n",
        "  \n",
        "  def log(self):\n",
        "    out = Value(log(self.data), (self,), 'log')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad += (1 / self.data) * out.grad\n",
        "      print(self, (1 / self.data))\n",
        "    out._backward = _backward\n",
        "\n",
        "    return out\n",
        "  \n",
        "  def __radd__(self, other):\n",
        "    return self + other\n",
        "\n",
        "  def backward(self): # exactly as in video\n",
        "    topo = []\n",
        "    visited = set()\n",
        "    def build_topo(v):\n",
        "      if v not in visited:\n",
        "        visited.add(v)\n",
        "        for child in v._prev:\n",
        "          build_topo(child)\n",
        "        topo.append(v)\n",
        "    build_topo(self)\n",
        "\n",
        "    self.grad = 1.0\n",
        "    for node in reversed(topo):\n",
        "      node._backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VgWvwVQNAvnI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Value(data=0.04177257051535045), Value(data=0.839024507462532), Value(data=0.005653302662216329), Value(data=0.11354961935990121)]\n",
            "2.1755153626167147\n",
            "Value(data=-2.1755153626167147) -1.0\n",
            "Value(data=0.11354961935990121) 8.806722608469958\n",
            "OK for dim 0: expected 0.041772570515350445, yours returns 0.041772570515350445\n",
            "OK for dim 1: expected 0.8390245074625319, yours returns 0.8390245074625319\n",
            "OK for dim 2: expected 0.005653302662216329, yours returns 0.005653302662216329\n",
            "OK for dim 3: expected -0.8864503806400986, yours returns -0.886450380640099\n"
          ]
        }
      ],
      "source": [
        "# without referencing our code/video __too__ much, make this cell work\n",
        "# you'll have to implement (in some cases re-implemented) a number of functions\n",
        "# of the Value object, similar to what we've seen in the video.\n",
        "# instead of the squared error loss this implements the negative log likelihood\n",
        "# loss, which is very often used in classification.\n",
        "\n",
        "# this is the softmax function\n",
        "# https://en.wikipedia.org/wiki/Softmax_function\n",
        "def softmax(logits):\n",
        "  counts = [logit.exp() for logit in logits]\n",
        "  denominator = sum(counts)\n",
        "  out = [c / denominator for c in counts]\n",
        "  return out\n",
        "\n",
        "# this is the negative log likelihood loss function, pervasive in classification\n",
        "logits = [Value(0.0), Value(3.0), Value(-2.0), Value(1.0)]\n",
        "probs = softmax(logits)\n",
        "print(probs)\n",
        "loss = -probs[3].log() # dim 3 acts as the label for this input example\n",
        "print(loss.data)\n",
        "loss.backward()\n",
        "\n",
        "ans = [0.041772570515350445, 0.8390245074625319, 0.005653302662216329, -0.8864503806400986]\n",
        "for dim in range(4):\n",
        "  ok = 'OK' if abs(logits[dim].grad - ans[dim]) < 1e-5 else 'WRONG!'\n",
        "  print(f\"{ok} for dim {dim}: expected {ans[dim]}, yours returns {logits[dim].grad}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q7ca1SVAGG1S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(0.0418, grad_fn=<DivBackward0>), tensor(0.8390, grad_fn=<DivBackward0>), tensor(0.0057, grad_fn=<DivBackward0>), tensor(0.1135, grad_fn=<DivBackward0>)]\n",
            "tensor(2.1755)\n",
            "OK for dim 0: expected 0.041772570515350445, yours returns 0.041772566735744476\n",
            "OK for dim 1: expected 0.8390245074625319, yours returns 0.8390244245529175\n",
            "OK for dim 2: expected 0.005653302662216329, yours returns 0.005653302185237408\n",
            "OK for dim 3: expected -0.8864503806400986, yours returns -0.8864503502845764\n"
          ]
        }
      ],
      "source": [
        "# verify the gradient using the torch library\n",
        "# torch should give you the exact same gradient\n",
        "import torch\n",
        "\n",
        "logits = [torch.tensor(0.0, requires_grad=True), torch.tensor(3.0, requires_grad=True), torch.tensor(-2.0, requires_grad=True), torch.tensor(1.0, requires_grad=True)]\n",
        "probs = softmax(logits)\n",
        "print(probs)\n",
        "loss = -probs[3].log() # dim 3 acts as the label for this input example\n",
        "print(loss.data)\n",
        "loss.backward()\n",
        "\n",
        "for dim in range(4):\n",
        "  ok = 'OK' if abs(logits[dim].grad - ans[dim]) < 1e-5 else 'WRONG!'\n",
        "  print(f\"{ok} for dim {dim}: expected {ans[dim]}, yours returns {logits[dim].grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an implementation of the backpropagation algorithm an a way to train a linear regression model using the following data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4dc395d7b0>"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import math, random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def y_fn(x):\n",
        "    return 15 + 2*x + random.random()*50\n",
        "\n",
        "X = [random.randrange(0, 100) for _ in range(50)]\n",
        "y = [y_fn(x) for x in X]\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X = X / X.std()\n",
        "y = y / y.std()\n",
        "\n",
        "plt.scatter(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an object capable of keeping and calculating the gradient, and implement the backpropagation algorithm as a method. Create a linear regression model with only tow parameters (y=m*x+b), and use the Mean Squared Error as the loss function. Moreover, you must create a train function to update the parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9485482320662991\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([0.97393441]), 0.6205889935008362)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(X.reshape(-1,1), y)\n",
        "print(reg.score(X.reshape(-1,1), y))\n",
        "reg.coef_, reg.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GradVal():\n",
        "    def __init__(self, data, children = tuple(), _op = ''):\n",
        "        self.data = data\n",
        "        self.children = children\n",
        "        self._op = _op\n",
        "        self.grad = 0\n",
        "        self._backward = lambda: None\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        try:\n",
        "            other = other if isinstance(other, GradVal) else GradVal(other)\n",
        "            out = GradVal(self.data * other.data, (self, other), '*')\n",
        "        except Exception as e:\n",
        "            print(f'Error multiplying {self, other}')\n",
        "            raise e\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += other.data * out.grad\n",
        "            other.grad += self.grad * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "    \n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, GradVal) else GradVal(other)\n",
        "        out = GradVal(self.data + other.data, (self, other), '+')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad\n",
        "            other.grad += out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "    \n",
        "    def __radd__(self, other):\n",
        "        return self + other\n",
        "    \n",
        "    def __sub__(self, other):\n",
        "        return self + -1 * other\n",
        "    \n",
        "    def backward(self):\n",
        "        self._backward()\n",
        "        for child in self.children:\n",
        "            child.backward()\n",
        "    \n",
        "    def backpropagation(self):\n",
        "        self.grad = 1.0\n",
        "        self.backward()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f'GradVal({self.data:.5f})'\n",
        "\n",
        "\n",
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.parameters = [GradVal(random.random()), GradVal(random.random())]\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        return self.parameters[0]*x + self.parameters[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "def MSE(y_preds, y_reals):\n",
        "    return sum([(y_preds[i] - y_reals[i]) * (y_preds[i] - y_reals[i]) for i in range(len(y_preds))]) * (1/len(y_preds))\n",
        "\n",
        "def train(loss_fn, model, X, y, lr=1e-1, epochs = 10):\n",
        "    for e in range(epochs):\n",
        "        print(f'Epoch {e+1}')\n",
        "       \n",
        "        loss = loss_fn([model(x) for x in X], y)\n",
        "        print(f'loss:', loss)\n",
        "        loss.backpropagation()\n",
        "\n",
        "        for p in model.parameters:\n",
        "            p.data -= lr * p.grad\n",
        "            p.grad = 0.0\n",
        "        print(model.parameters)\n",
        "        print([p.grad for p in model.parameters])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[GradVal(0.86538), GradVal(0.41385)]"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Model()\n",
        "model.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "loss: GradVal(0.23261)\n",
            "[GradVal(1.13267), GradVal(0.49699)]\n",
            "[0.0, 0.0]\n",
            "Epoch 2\n",
            "loss: GradVal(0.10758)\n",
            "[GradVal(0.98451), GradVal(0.46146)]\n",
            "[0.0, 0.0]\n",
            "Epoch 3\n",
            "loss: GradVal(0.07093)\n",
            "[GradVal(1.06062), GradVal(0.48957)]\n",
            "[0.0, 0.0]\n",
            "Epoch 4\n",
            "loss: GradVal(0.06002)\n",
            "[GradVal(1.01590), GradVal(0.48300)]\n",
            "[0.0, 0.0]\n",
            "Epoch 5\n",
            "loss: GradVal(0.05662)\n",
            "[GradVal(1.03651), GradVal(0.49480)]\n",
            "[0.0, 0.0]\n",
            "Epoch 6\n",
            "loss: GradVal(0.05543)\n",
            "[GradVal(1.02202), GradVal(0.49636)]\n",
            "[0.0, 0.0]\n",
            "Epoch 7\n",
            "loss: GradVal(0.05489)\n",
            "[GradVal(1.02659), GradVal(0.50313)]\n",
            "[0.0, 0.0]\n",
            "Epoch 8\n",
            "loss: GradVal(0.05455)\n",
            "[GradVal(1.02101), GradVal(0.50679)]\n",
            "[0.0, 0.0]\n",
            "Epoch 9\n",
            "loss: GradVal(0.05429)\n",
            "[GradVal(1.02103), GradVal(0.51183)]\n",
            "[0.0, 0.0]\n",
            "Epoch 10\n",
            "loss: GradVal(0.05407)\n",
            "[GradVal(1.01815), GradVal(0.51585)]\n",
            "[0.0, 0.0]\n",
            "Epoch 11\n",
            "loss: GradVal(0.05386)\n",
            "[GradVal(1.01694), GradVal(0.52016)]\n",
            "[0.0, 0.0]\n",
            "Epoch 12\n",
            "loss: GradVal(0.05367)\n",
            "[GradVal(1.01494), GradVal(0.52406)]\n",
            "[0.0, 0.0]\n",
            "Epoch 13\n",
            "loss: GradVal(0.05350)\n",
            "[GradVal(1.01348), GradVal(0.52793)]\n",
            "[0.0, 0.0]\n",
            "Epoch 14\n",
            "loss: GradVal(0.05334)\n",
            "[GradVal(1.01182), GradVal(0.53157)]\n",
            "[0.0, 0.0]\n",
            "Epoch 15\n",
            "loss: GradVal(0.05319)\n",
            "[GradVal(1.01037), GradVal(0.53511)]\n",
            "[0.0, 0.0]\n",
            "Epoch 16\n",
            "loss: GradVal(0.05306)\n",
            "[GradVal(1.00890), GradVal(0.53849)]\n",
            "[0.0, 0.0]\n",
            "Epoch 17\n",
            "loss: GradVal(0.05293)\n",
            "[GradVal(1.00753), GradVal(0.54175)]\n",
            "[0.0, 0.0]\n",
            "Epoch 18\n",
            "loss: GradVal(0.05282)\n",
            "[GradVal(1.00619), GradVal(0.54487)]\n",
            "[0.0, 0.0]\n",
            "Epoch 19\n",
            "loss: GradVal(0.05271)\n",
            "[GradVal(1.00491), GradVal(0.54787)]\n",
            "[0.0, 0.0]\n",
            "Epoch 20\n",
            "loss: GradVal(0.05261)\n",
            "[GradVal(1.00369), GradVal(0.55076)]\n",
            "[0.0, 0.0]\n",
            "Epoch 21\n",
            "loss: GradVal(0.05252)\n",
            "[GradVal(1.00251), GradVal(0.55352)]\n",
            "[0.0, 0.0]\n",
            "Epoch 22\n",
            "loss: GradVal(0.05244)\n",
            "[GradVal(1.00137), GradVal(0.55618)]\n",
            "[0.0, 0.0]\n",
            "Epoch 23\n",
            "loss: GradVal(0.05236)\n",
            "[GradVal(1.00029), GradVal(0.55873)]\n",
            "[0.0, 0.0]\n",
            "Epoch 24\n",
            "loss: GradVal(0.05229)\n",
            "[GradVal(0.99924), GradVal(0.56118)]\n",
            "[0.0, 0.0]\n",
            "Epoch 25\n",
            "loss: GradVal(0.05223)\n",
            "[GradVal(0.99824), GradVal(0.56354)]\n",
            "[0.0, 0.0]\n",
            "Epoch 26\n",
            "loss: GradVal(0.05217)\n",
            "[GradVal(0.99728), GradVal(0.56580)]\n",
            "[0.0, 0.0]\n",
            "Epoch 27\n",
            "loss: GradVal(0.05211)\n",
            "[GradVal(0.99635), GradVal(0.56797)]\n",
            "[0.0, 0.0]\n",
            "Epoch 28\n",
            "loss: GradVal(0.05206)\n",
            "[GradVal(0.99546), GradVal(0.57006)]\n",
            "[0.0, 0.0]\n",
            "Epoch 29\n",
            "loss: GradVal(0.05201)\n",
            "[GradVal(0.99461), GradVal(0.57206)]\n",
            "[0.0, 0.0]\n",
            "Epoch 30\n",
            "loss: GradVal(0.05197)\n",
            "[GradVal(0.99379), GradVal(0.57398)]\n",
            "[0.0, 0.0]\n",
            "Epoch 31\n",
            "loss: GradVal(0.05193)\n",
            "[GradVal(0.99300), GradVal(0.57583)]\n",
            "[0.0, 0.0]\n",
            "Epoch 32\n",
            "loss: GradVal(0.05189)\n",
            "[GradVal(0.99225), GradVal(0.57760)]\n",
            "[0.0, 0.0]\n",
            "Epoch 33\n",
            "loss: GradVal(0.05186)\n",
            "[GradVal(0.99152), GradVal(0.57931)]\n",
            "[0.0, 0.0]\n",
            "Epoch 34\n",
            "loss: GradVal(0.05183)\n",
            "[GradVal(0.99083), GradVal(0.58094)]\n",
            "[0.0, 0.0]\n",
            "Epoch 35\n",
            "loss: GradVal(0.05180)\n",
            "[GradVal(0.99016), GradVal(0.58251)]\n",
            "[0.0, 0.0]\n",
            "Epoch 36\n",
            "loss: GradVal(0.05177)\n",
            "[GradVal(0.98951), GradVal(0.58402)]\n",
            "[0.0, 0.0]\n",
            "Epoch 37\n",
            "loss: GradVal(0.05175)\n",
            "[GradVal(0.98890), GradVal(0.58547)]\n",
            "[0.0, 0.0]\n",
            "Epoch 38\n",
            "loss: GradVal(0.05172)\n",
            "[GradVal(0.98830), GradVal(0.58686)]\n",
            "[0.0, 0.0]\n",
            "Epoch 39\n",
            "loss: GradVal(0.05170)\n",
            "[GradVal(0.98773), GradVal(0.58820)]\n",
            "[0.0, 0.0]\n",
            "Epoch 40\n",
            "loss: GradVal(0.05168)\n",
            "[GradVal(0.98719), GradVal(0.58948)]\n",
            "[0.0, 0.0]\n",
            "Epoch 41\n",
            "loss: GradVal(0.05166)\n",
            "[GradVal(0.98666), GradVal(0.59071)]\n",
            "[0.0, 0.0]\n",
            "Epoch 42\n",
            "loss: GradVal(0.05165)\n",
            "[GradVal(0.98616), GradVal(0.59190)]\n",
            "[0.0, 0.0]\n",
            "Epoch 43\n",
            "loss: GradVal(0.05163)\n",
            "[GradVal(0.98567), GradVal(0.59304)]\n",
            "[0.0, 0.0]\n",
            "Epoch 44\n",
            "loss: GradVal(0.05162)\n",
            "[GradVal(0.98521), GradVal(0.59413)]\n",
            "[0.0, 0.0]\n",
            "Epoch 45\n",
            "loss: GradVal(0.05161)\n",
            "[GradVal(0.98476), GradVal(0.59518)]\n",
            "[0.0, 0.0]\n",
            "Epoch 46\n",
            "loss: GradVal(0.05159)\n",
            "[GradVal(0.98433), GradVal(0.59618)]\n",
            "[0.0, 0.0]\n",
            "Epoch 47\n",
            "loss: GradVal(0.05158)\n",
            "[GradVal(0.98392), GradVal(0.59715)]\n",
            "[0.0, 0.0]\n",
            "Epoch 48\n",
            "loss: GradVal(0.05157)\n",
            "[GradVal(0.98352), GradVal(0.59808)]\n",
            "[0.0, 0.0]\n",
            "Epoch 49\n",
            "loss: GradVal(0.05156)\n",
            "[GradVal(0.98314), GradVal(0.59897)]\n",
            "[0.0, 0.0]\n",
            "Epoch 50\n",
            "loss: GradVal(0.05155)\n",
            "[GradVal(0.98278), GradVal(0.59983)]\n",
            "[0.0, 0.0]\n",
            "Epoch 51\n",
            "loss: GradVal(0.05155)\n",
            "[GradVal(0.98243), GradVal(0.60065)]\n",
            "[0.0, 0.0]\n",
            "Epoch 52\n",
            "loss: GradVal(0.05154)\n",
            "[GradVal(0.98209), GradVal(0.60144)]\n",
            "[0.0, 0.0]\n",
            "Epoch 53\n",
            "loss: GradVal(0.05153)\n",
            "[GradVal(0.98177), GradVal(0.60220)]\n",
            "[0.0, 0.0]\n",
            "Epoch 54\n",
            "loss: GradVal(0.05153)\n",
            "[GradVal(0.98146), GradVal(0.60293)]\n",
            "[0.0, 0.0]\n",
            "Epoch 55\n",
            "loss: GradVal(0.05152)\n",
            "[GradVal(0.98116), GradVal(0.60363)]\n",
            "[0.0, 0.0]\n",
            "Epoch 56\n",
            "loss: GradVal(0.05152)\n",
            "[GradVal(0.98087), GradVal(0.60430)]\n",
            "[0.0, 0.0]\n",
            "Epoch 57\n",
            "loss: GradVal(0.05151)\n",
            "[GradVal(0.98060), GradVal(0.60495)]\n",
            "[0.0, 0.0]\n",
            "Epoch 58\n",
            "loss: GradVal(0.05151)\n",
            "[GradVal(0.98034), GradVal(0.60557)]\n",
            "[0.0, 0.0]\n",
            "Epoch 59\n",
            "loss: GradVal(0.05150)\n",
            "[GradVal(0.98008), GradVal(0.60616)]\n",
            "[0.0, 0.0]\n",
            "Epoch 60\n",
            "loss: GradVal(0.05150)\n",
            "[GradVal(0.97984), GradVal(0.60673)]\n",
            "[0.0, 0.0]\n",
            "Epoch 61\n",
            "loss: GradVal(0.05149)\n",
            "[GradVal(0.97960), GradVal(0.60728)]\n",
            "[0.0, 0.0]\n",
            "Epoch 62\n",
            "loss: GradVal(0.05149)\n",
            "[GradVal(0.97938), GradVal(0.60781)]\n",
            "[0.0, 0.0]\n",
            "Epoch 63\n",
            "loss: GradVal(0.05149)\n",
            "[GradVal(0.97916), GradVal(0.60832)]\n",
            "[0.0, 0.0]\n",
            "Epoch 64\n",
            "loss: GradVal(0.05148)\n",
            "[GradVal(0.97896), GradVal(0.60880)]\n",
            "[0.0, 0.0]\n",
            "Epoch 65\n",
            "loss: GradVal(0.05148)\n",
            "[GradVal(0.97876), GradVal(0.60927)]\n",
            "[0.0, 0.0]\n",
            "Epoch 66\n",
            "loss: GradVal(0.05148)\n",
            "[GradVal(0.97857), GradVal(0.60972)]\n",
            "[0.0, 0.0]\n",
            "Epoch 67\n",
            "loss: GradVal(0.05148)\n",
            "[GradVal(0.97838), GradVal(0.61015)]\n",
            "[0.0, 0.0]\n",
            "Epoch 68\n",
            "loss: GradVal(0.05148)\n",
            "[GradVal(0.97821), GradVal(0.61056)]\n",
            "[0.0, 0.0]\n",
            "Epoch 69\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97804), GradVal(0.61096)]\n",
            "[0.0, 0.0]\n",
            "Epoch 70\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97787), GradVal(0.61134)]\n",
            "[0.0, 0.0]\n",
            "Epoch 71\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97772), GradVal(0.61171)]\n",
            "[0.0, 0.0]\n",
            "Epoch 72\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97757), GradVal(0.61206)]\n",
            "[0.0, 0.0]\n",
            "Epoch 73\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97742), GradVal(0.61240)]\n",
            "[0.0, 0.0]\n",
            "Epoch 74\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97729), GradVal(0.61272)]\n",
            "[0.0, 0.0]\n",
            "Epoch 75\n",
            "loss: GradVal(0.05147)\n",
            "[GradVal(0.97715), GradVal(0.61303)]\n",
            "[0.0, 0.0]\n",
            "Epoch 76\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97703), GradVal(0.61333)]\n",
            "[0.0, 0.0]\n",
            "Epoch 77\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97690), GradVal(0.61362)]\n",
            "[0.0, 0.0]\n",
            "Epoch 78\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97679), GradVal(0.61390)]\n",
            "[0.0, 0.0]\n",
            "Epoch 79\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97667), GradVal(0.61416)]\n",
            "[0.0, 0.0]\n",
            "Epoch 80\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97656), GradVal(0.61442)]\n",
            "[0.0, 0.0]\n",
            "Epoch 81\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97646), GradVal(0.61466)]\n",
            "[0.0, 0.0]\n",
            "Epoch 82\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97636), GradVal(0.61490)]\n",
            "[0.0, 0.0]\n",
            "Epoch 83\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97626), GradVal(0.61512)]\n",
            "[0.0, 0.0]\n",
            "Epoch 84\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97617), GradVal(0.61534)]\n",
            "[0.0, 0.0]\n",
            "Epoch 85\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97608), GradVal(0.61555)]\n",
            "[0.0, 0.0]\n",
            "Epoch 86\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97600), GradVal(0.61575)]\n",
            "[0.0, 0.0]\n",
            "Epoch 87\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97592), GradVal(0.61594)]\n",
            "[0.0, 0.0]\n",
            "Epoch 88\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97584), GradVal(0.61612)]\n",
            "[0.0, 0.0]\n",
            "Epoch 89\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97576), GradVal(0.61630)]\n",
            "[0.0, 0.0]\n",
            "Epoch 90\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97569), GradVal(0.61647)]\n",
            "[0.0, 0.0]\n",
            "Epoch 91\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97562), GradVal(0.61663)]\n",
            "[0.0, 0.0]\n",
            "Epoch 92\n",
            "loss: GradVal(0.05146)\n",
            "[GradVal(0.97555), GradVal(0.61679)]\n",
            "[0.0, 0.0]\n",
            "Epoch 93\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97549), GradVal(0.61694)]\n",
            "[0.0, 0.0]\n",
            "Epoch 94\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97543), GradVal(0.61708)]\n",
            "[0.0, 0.0]\n",
            "Epoch 95\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97537), GradVal(0.61722)]\n",
            "[0.0, 0.0]\n",
            "Epoch 96\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97531), GradVal(0.61736)]\n",
            "[0.0, 0.0]\n",
            "Epoch 97\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97526), GradVal(0.61748)]\n",
            "[0.0, 0.0]\n",
            "Epoch 98\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97520), GradVal(0.61761)]\n",
            "[0.0, 0.0]\n",
            "Epoch 99\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97515), GradVal(0.61773)]\n",
            "[0.0, 0.0]\n",
            "Epoch 100\n",
            "loss: GradVal(0.05145)\n",
            "[GradVal(0.97511), GradVal(0.61784)]\n",
            "[0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "train(MSE, model, X, y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[GradVal(0.97511), GradVal(0.61784)]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4dc28308e0>"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_preds = [model(x) for x in X]\n",
        "\n",
        "plt.scatter(X, y)\n",
        "plt.scatter(X, [y.data for y in y_preds])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09194145093705215"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "p1 = 0.9\n",
        "p2= 0.8\n",
        "p3 = 0.3\n",
        "\n",
        "n = 100\n",
        "k = 20\n",
        "\n",
        "def get_p(k, n):\n",
        "    p = 0\n",
        "    for r in range(k,n+1):\n",
        "        # print('registered', r)\n",
        "        p_r = (math.comb(n,r)* p1**r * (1-p1)**(n-r))\n",
        "        for v in range(k,r+1):\n",
        "            # print('voted', v)\n",
        "            p_v = (math.comb(r,v)* p2**v * (1-p2)**(r-v))\n",
        "            \n",
        "            # print('kodos', k)\n",
        "            p_k = (math.comb(v,k)* p3**k * (1-p3)**(v-k))\n",
        "\n",
        "            p += p_r*p_v*p_k\n",
        "    return p\n",
        "\n",
        "get_p(k,n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "15360"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = 10\n",
        "k = 3\n",
        "print(math.comb(n,k))\n",
        "result = 0\n",
        "for i in range(k,n+1):\n",
        "    result += math.comb(n,i)*math.comb(i,k)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k,n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(math.comb(i,k), math.factorial(i)-1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m math\u001b[38;5;241m.\u001b[39mcomb(n,k)\u001b[38;5;241m*\u001b[39mresult\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "result = 0\n",
        "for i in range(k,n+1):\n",
        "    result += (math.factorial(n-i))/((math.factorial(n-i)-1)*math.factorial(i-k)*math.factorial(k))\n",
        "    # print(math.comb(i,k), math.factorial(i)-1)\n",
        "math.comb(n,k)*result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 0.2001209489999999 0.2001209489999999\n",
            "5 0.10291934519999994 0.30304029419999984\n",
            "6 0.03675690899999999 0.33979720319999984\n",
            "7 0.009001691999999995 0.34879889519999985\n",
            "8 0.0014467004999999993 0.35024559569999986\n",
            "9 0.00013778099999999996 0.35038337669999986\n",
            "10 5.9048999999999975e-06 0.3503892815999999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.3503892815999999"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p1= 0.3\n",
        "result = 0\n",
        "for i in range(4, 10+1):\n",
        "    res = math.comb(10,i) * p1**i * (1-p1)**(10-i)\n",
        "    result += res\n",
        "    print(i, res, result)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.028247524899999984 0.028247524899999984\n",
            "1 0.12106082099999993 0.14930834589999992\n",
            "2 0.23347444049999988 0.3827827863999998\n",
            "3 0.2668279319999998 0.6496107183999996\n",
            "4 0.2001209489999999 0.8497316673999995\n",
            "5 0.10291934519999994 0.9526510125999994\n",
            "6 0.03675690899999999 0.9894079215999994\n",
            "7 0.009001691999999995 0.9984096135999994\n",
            "8 0.0014467004999999993 0.9998563140999993\n",
            "9 0.00013778099999999996 0.9999940950999993\n",
            "10 5.9048999999999975e-06 0.9999999999999992\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9999999999999992"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = 0\n",
        "for i in range(0, 10+1):\n",
        "    res = math.comb(10,i) * p1**i * (1-p1)**(10-i)\n",
        "    result += res\n",
        "    print(i, res, result)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1013"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n= 10\n",
        "result = 0\n",
        "for k in range(2,n+1):\n",
        "    result += math.comb(n,k)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1440"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.factorial(3)*math.factorial(2)*math.factorial(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12600.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "5*(math.factorial(10) / (math.factorial(3)*math.factorial(2)*math.factorial(5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math.comb(10,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "252\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "61236"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n = 10\n",
        "k = 5\n",
        "\n",
        "print(math.comb(n,5))\n",
        "result = 0\n",
        "for i in range(k,n+1):\n",
        "    for v in range(k, i+1):\n",
        "        result += math.comb(n,i)*math.comb(i,v)*math.comb(v,k)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.9934228934677878"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "math.log(61236, 252)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
